import fs from 'fs'
import path from 'path'
import rdir from 'recursive-readdir'
import { unified } from 'unified'
import remarkParser from 'remark-parse'
import remarkCompiler from 'remark-stringify'
import remarkFrontmatter from 'remark-frontmatter'
import remarkFrontmatterExtractor from 'remark-extract-frontmatter'
import { readSync } from 'to-vfile'
import yaml from 'js-yaml'
import { mdIntro } from './md-intro.mjs'

// Some arbitrary future time
const future = new Date('10-12-2026').getTime()

export const header = `/*
 *
 * This page was auto-generated by the prebuild script
 * Any changes you make to it will be lost on the next (pre)build.
 */
`

/*
 * There's an issue in crowdin where it changes the frontmatter marker:
 * ---
 * into this:
 * - - -
 * which breaks stuff. So this method takes the input and replaces all
 * - - - with ---
 */
export const fixCrowdinBugs = (md) => {
  md.value = md.value.split('- - -\n').join('---\n')
  return md
}

/*
 * Helper method to get the title and meta data from an MDX file
 *
 * Parameters:
 *
 *  - file: the full path to the file
 */
const mdxMetaInfo = async (file) => {
  let result
  try {
    result = await unified()
      .use(remarkParser)
      .use(remarkCompiler)
      .use(remarkFrontmatter)
      .use(remarkFrontmatterExtractor, { yaml: yaml.load })
      .process(fixCrowdinBugs(readSync(file, { encoding: 'utf-8' })))
  } catch (err) {
    console.log(err)
  }

  return result
}

/*
 * Helper method to get a list of MDX files in a folder.
 * Will traverse recursively to get all files from a given root folder.
 *
 * Parameters:
 *
 *  - folder: the root folder to look in
 *  - lang: the language files to looks for
 *
 *  Exported because it's also used by the Algolia index script
 */
export const getMdxFileList = async (folder, locales) => {
  let allFiles
  try {
    allFiles = await rdir(folder)
  } catch (err) {
    console.log(err)
    return false
  }

  // Filter out all that's not a language-specific markdown file
  // and avoid including the 'ui' files
  const files = {}
  for (const file of allFiles) {
    const lang = file.slice(-5, -3)
    if (!locales || locales.includes(lang)) {
      files[lang] = files[lang] || []
      files[lang].push(file)
    }
  }

  for (const lang in files) files[lang].sort()

  return files
}

/*
 * Helper method to get the website slug (path) from the file path
 */
export const fileToSlug = (file, site, lang) =>
  file.slice(-6) === `/${lang}.md` ? file.split(`/markdown/${site}/`).pop().slice(0, -6) : false

/*
 * Main method that does what needs doing
 */
export const prebuildMdxFromFolder = async (site, allPages, folder = false) => {
  // Say hi
  console.log()
  console.log(`Compiling list of ${folder || 'docs'} pages for freesewing.${site}`)

  // Setup MDX root path
  const root = ['..', '..', 'markdown', site]
  if (folder) root.push(folder)
  const mdxRoot = path.resolve(...root)

  // Languages
  const locales = await import(`../../${site}/site.config.mjs`).then(
    (mod) => mod.siteConfig.languages
  )

  const allFiles = await getMdxFileList(mdxRoot, locales)

  const sections = new Set()
  const pages = {}
  // Loop over languages
  for (const lang of locales) {
    pages[lang] = {}
    // Get list of filenames
    const list = allFiles[lang]
    if (!list) continue

    if (folder) pages[lang][folder] = { s: folder }
    // Loop over files
    for (const file of list) {
      const slug = fileToSlug(file, site, lang)

      const sectionDepth = folder ? 2 : 1
      const section = slug.split('/').slice(0, sectionDepth)
      if (section.length === sectionDepth) sections.add(section.join('/'))

      const meta = await mdxMetaInfo(file)
      // minify the metadat
      if (meta.data?.title) {
        const minMeta = { t: meta.data.title }

        if (meta.data.order) minMeta.o = `${meta.data.order}${meta.data.title}`
        else if (meta.data.date) {
          minMeta.d = meta.data.date
          minMeta.o = (future - new Date(meta.data.date).getTime()) / 100000
        }

        if (meta.data.image) minMeta.i = meta.data.image
        if (meta.data.author) minMeta.a = meta.data.author
        pages[lang][slug] = minMeta
      } else {
        if (pages.en[slug]) {
          console.log(`⚠️l Falling back to EN metadata for ${lang} ${slug}`)
          pages[lang][slug] = pages.en[slug]
        } else {
          console.log(`❌ [${lang}] Failed to extract meta info from: ${slug}`)
          if (meta.messages.length > 0) console.log(meta.messages)
        }
      }

      if (process.env.GENERATE_OG_IMAGES) {
        intro = await mdIntro(lang, site, slug)
        //  // Create og image
        //  await generateOgImage({ lang, site, slug, title: meta.data.title, intro})
      }
    }

    allPages[lang] = allPages[lang] || {}
    Object.assign(allPages[lang], pages[lang])
  }

  return { pages, sections }
}

export const prebuildDocs = async (site, nav) => {
  const { pages, sections } = await prebuildMdxFromFolder(
    site,
    nav,
    site === 'org' ? 'docs' : false
  )

  // Write files with MDX paths
  fs.mkdirSync(path.resolve('..', site, 'prebuild', 'docs'), { recursive: true })
  let allPaths = ``
  // do one for each language so we can import smaller bundles
  for (const lang in pages) {
    fs.writeFileSync(
      path.resolve('..', site, 'prebuild', 'docs', `mdx-paths.${lang}.mjs`),
      `${header}export const mdxPaths = ${JSON.stringify(Object.keys(pages[lang]))}`
    )
    allPaths += `import { mdxPaths as ${lang} } from './mdx-paths.${lang}.mjs'` + '\n'
  }

  // Write umbrella file
  fs.writeFileSync(
    path.resolve('..', site, 'prebuild', `mdx-paths.mjs`),
    `${allPaths}
    ${header}export const mdxPaths = { ${Object.keys(pages).join(',')} }`
  )

  // Write loader file
  const sectionLoaders = [...sections].map(
    (s) => `case '${s.split('/').slice(-1)}':
    return () => import(\`${site}markdown/${s}\${splitPath}/\${lang}.md\`)
  `
  )

  fs.writeFileSync(
    path.resolve('..', site, 'prebuild', 'docs', `loader.mjs`),
    `${header}export const getLoader = (path, lang) => {
  const split = path.split('/')
  const section = split.shift()
  const splitPath = (split.length ? '/' : '') + split.join('/')

  switch (section) {
  ${sectionLoaders.join('')}
  default:
    return () =>
      import(
        /* webpackExclude: /(${[...sections]
          .map((s) => s.replace('/', '\\/'))
          .join('|')})/ */ \`${site}markdown\${path}/\${lang}.md\`
      )
  }
}`
  )

  return pages
}
